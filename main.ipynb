{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial value\n",
    "\n",
    "GWP_0 = 8.5e13 #initial world GDP, used by takeoff model\n",
    "RH_0=1.7e11 #initial research input to hardware (only relevant for exogeneous modelling)\n",
    "RS_0=1.7e10 #initial research input to software (only releveant for exogeneous modelling)\n",
    "HS_0 =  2e28 #https://docs.google.com/document/d/1rw1pTbLi2brrEP0DcsZMAVhlKp6TKGKNUSFRkkdP_hs/edit#bookmark=id.b15qyylbeqxp\n",
    "K_0= 6.1e14 #cumulative sum of depreciation adjusted capital investments\n",
    "L_0 = 4e9\n",
    "QH_0=2.2e9 #cumulative hardware research (USD) at start of simulation, read from graph (unsure how this is determined)\n",
    "QS_0=1e8 #at start of simulation, no software research done\n",
    "SK_0=0.5 #initial capital factor share\n",
    "SCog_0=0.5 #initial cognitive factor share\n",
    "SC_0=0.01 #initial factor share of compute in cognitive output production\n",
    "SL_0=0.99  #initial factor share of labour in cognitive output production\n",
    "\n",
    "\n",
    "S_0=1 \n",
    "H_0=1.5e17 #needs to be updated\n",
    "C_eff_0=HS_0*S_0 #initial stocks of effective compute\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### utils\n",
    "\n",
    "def construct_automation_thresholds(threshold_100,training_FLOP_GAP):\n",
    "    ##NOTE: the actual FTM sets 0,5,10,20 and 50 by hand then interpolates in log space between these\n",
    "\n",
    "    threshold_20=threshold_100-training_FLOP_GAP\n",
    "    threshold_0=threshold_20-(0.5*training_FLOP_GAP)\n",
    "    requirements_0_20=np.logspace(threshold_0,threshold_20,21)\n",
    "    requirements_20_100=np.logspace(threshold_20,threshold_100,80)\n",
    "    training_requirements=np.concatenate((requirements_0_20[:-1],requirements_20_100),axis=0)\n",
    "\n",
    "    return training_requirements\n",
    "\n",
    "def construct_baseline_runtime_efficiencies(runtime_reqs_100,runtime_FLOP_GAP):\n",
    "\n",
    "    runtime_reqs_20=runtime_reqs_100-runtime_FLOP_GAP\n",
    "    runtime_reqs_0=runtime_reqs_20-(0.5*runtime_FLOP_GAP)\n",
    "    runtime_reqs_0_20 = np.logspace(runtime_reqs_0,runtime_reqs_20,21)\n",
    "    runtime_reqs_20_100 = np.logspace(runtime_reqs_20,runtime_reqs_100,80)\n",
    "    runtime_reqs = np.concatenate((runtime_reqs_0_20[:-1],runtime_reqs_20_100),axis=0)\n",
    "\n",
    "    return runtime_reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iyngkarrankumar/opt/anaconda3/envs/scalingtrends/lib/python3.11/site-packages/numpy/core/function_base.py:298: RuntimeWarning: overflow encountered in power\n",
      "  return _nx.power(base, y)\n"
     ]
    }
   ],
   "source": [
    "# parameter dump\n",
    "\n",
    "\n",
    "HS_depreciation_rate = 0.2 #hardware stock deprecitation rate\n",
    "s_K = 0.2 #savings rate - 0.2/year\n",
    "f_GWP_H = 8e-4 #fraction of world output spent on hardware\n",
    "TFP = 1 #Total factor productivity - grows exogeneously in FTM (not implemented yet)\n",
    "T = 30 #number of years to run simulation for\n",
    "delta_T=1 #size of time increment. n_steps=T/delta_T\n",
    "n_steps = T/delta_T\n",
    "g_L = 0.01\n",
    "\n",
    "\n",
    "#### hardware research parameters \n",
    "alpha_H = 0.0092 #factor share of capital in hardware research production (used when shares are NOT computed)\n",
    "KS_H=None #capital share in hardware research productions\n",
    "CogS_H=None #cognitive share in hardware production\n",
    "f_K_H = 2e-3 #Â 2e-3 #fraction of capital stock for hardware research production\n",
    "f_L_H = 2e-3 #2e-3 #fraction of labour stock for hardware research production\n",
    "f_C_H = 2e-3\n",
    "f_GWP_H=2e-3 #t=0 fraction of GWP spent on hardware research (~ $140B on semiconductor R&D in 2022)\n",
    "rho_H = 1 #substitution parameter between capital and cogntiive labour for hardware research production\n",
    "rH = 7.4286 #hardware efficiency returns to hardware research - determined from comparing historical data on hardware (H) growth and research input ($) growth\n",
    "lambda_H = 0.7 #'stepping on toes' effect for hardware research (i.e: How much research per unit time contributes to hardware stock)\n",
    "ratio_initial_cumulative_hardware_input = 0.063 #ratio of 2022 hardware input to cumulative hardware input (in $)\n",
    "\n",
    "\n",
    "#### software research parameters \n",
    "alpha_S = 0.2571 #factor share of capital in software research production\n",
    "KS_S=None #capital share in software research productions\n",
    "CogS_S=None #cognitive share in software research production\n",
    "f_K_S = 2e-4 #2e-4 fraction of capital stock for software research production\n",
    "f_L_S = 2e-4 #2e-4 #fraciton of labour stock for software research production\n",
    "f_C_S = 2e-4\n",
    "f_GWP_S = 2e-4 #only needed for t=0. Payments to software researchers estimated as ~$10-20b, which is approx. 0.02% of GWP\n",
    "rho_S = 1 #substitution parameter between capital and cognitive labour for software research production\n",
    "rS = 1.7857\n",
    "ratio_initial_cumulative_software_input = 0.2 #ratio of initial software inputs to cumulative software research inputs\n",
    "\n",
    "#### GWP production\n",
    "alpha_G = 0.0002 #task weight non-compute capital in GWP production - should be computed each iteration\n",
    "KS_G=None #capital share in goods productions\n",
    "CogS_G=None #cognitive share in goods production\n",
    "f_K_GWP = 1-f_K_H-f_K_S #fraction of capital stock for producing GWP - not modelling hardware and software research endogeneously right now\n",
    "f_L_GWP = 1-f_L_H-f_L_S #fraction of labour for producing GWP - not modelling hardware and software research endogeneously right now\n",
    "f_C_GWP = 1-f_C_H-f_C_S #fraction of effective compute for producing GWP - not modelling hardware and software research endogeneously right now\n",
    "rho_G = -0.4 #substitution parameter between capital and cognitive labour for GWP production\n",
    "psi_G = -0.5 #substitution parameter between cognitive tasks in cognitive input production\n",
    "\n",
    "\n",
    "\n",
    "#### automation\n",
    "n_labour_tasks=100 #fixed for both production and research\n",
    "\n",
    "#automation - training\n",
    "f_C_T = 1.6e-4 #fraction of compute assigned to frontier training run in a year\n",
    "automation_training_task100 = 36 #compute threshold for last task (logspace)\n",
    "training_FLOP_GAP=4\n",
    "automation_training_threshold=construct_automation_thresholds(automation_training_task100,training_FLOP_GAP)\n",
    "\n",
    "#automation - runtime\n",
    "eta_0 = 6.0e23\n",
    "persecond_runtime_100 = 16 + 1 - np.log10(6) #bioanchors is 1e16 FLOP/s, adjust up by 1 OOM to account for TAI v.s. AGI, and down by 6x for AGI one-time benefits compared to human\n",
    "runtime_100 = persecond_runtime_100 + np.log10(60*60*24*365)\n",
    "runtime_FLOP_GAP=1\n",
    "baseline_runtime_requirements = construct_baseline_runtime_efficiencies(runtime_100,runtime_FLOP_GAP)\n",
    "delta=1.5 # Scaling factor of runtime efficiency C_T less than/greater than runtime requirements\n",
    "\n",
    "\n",
    "\n",
    "#### checks\n",
    "assert f_K_GWP+f_K_H+f_K_S==1\n",
    "assert f_L_GWP+f_L_H+f_L_S==1\n",
    "assert f_C_GWP+f_C_H+f_C_S==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#logging setup\n",
    "LOGGING=False\n",
    "logging_dict = {\n",
    "    't':None,\n",
    "    'year':None,\n",
    "\n",
    "    'GWP (2022 $)':None,\n",
    "    'HS (FLOP/year)':None,\n",
    "    'C_eff (2022 FLOP/year)':None,\n",
    "    'H (FLOP/$/year)':None,\n",
    "    'S (2022 FLOP/FLOP/year)':None,\n",
    "    'RS (2022 $)':None,\n",
    "\n",
    "    'Cog_G (2022 $)':None, #still no idea how to physically interpret this variable\n",
    "    'Automation index':None,\n",
    "    'C_eff_T':None,\n",
    "\n",
    "    'K (2022 $)':None,\n",
    "    'L (HLY/year)':None, #HLH - human labour years\n",
    "    'Capital to cognitive share ratio':None,\n",
    "    'alpha_G':None,\n",
    "    'Compute to labour share ratio':None,\n",
    "    'beta_0':None,\n",
    "    'beta_i':None,\n",
    "\n",
    "    'RH (2022 $)':None,\n",
    "    'QH (2022 $)':None,\n",
    "    'g_H':None,\n",
    "    'g_QH':None,\n",
    "\n",
    "    'RS (2022 $)':None,\n",
    "    'QS (2022 $)':None,\n",
    "    'g_S':None,\n",
    "    'g_QS':None,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#### bools\n",
    "\n",
    "##production bools\n",
    "GWP_ENDOGENEOUS,exg_g_GWP=True,0.02\n",
    "H_ENDOGENEOUS,g_H=False,0.5 #use derivate method of Jones 1995 research modeling, if not hardware (H) exogeneous\n",
    "S_ENDOGENEOUS,g_S=False,0.5 #use derivate method of Jones 1995 research modeling, if not software (S) exogeneous\n",
    "RH_ENDOGENEOUS,ex_g_RH=False,0.02 #produce hardware research each time step, if not hardware production (RH) exogeneous\n",
    "RS_ENDOGENEOUS,ex_g_RS=False,0.02 #produce software research each time step, if not  software production (RS) exogeneous\n",
    "COGNITIVES_INPUT_ENDOGENOUS,g_Cog=True,0.02 #'Produce' (calculate) cognitive inputs each time step, if not cognitive inputs (Cog) exogeneous\n",
    "COMPUTE_OUTER_WEIGHTS,alpha_G=True,0.0002 #compute outer weights to CES production function, if not constant\n",
    "COMPUTE_INNER_WEIGHTS,beta_0,beta_i = True,1,4e-11 #compute inner weights to CES production function, if not constant\n",
    "COMPUTE_RUNTIME_EFFICIENCIES = True\n",
    "\n",
    "\n",
    "##Research bools\n",
    "HARDWARE_PENALTY_FACTOR=False #apply penalty factor to hardware efficiency growth rate - leave for now\n",
    "SOFTWARE_PENALTY_FACTOR=False #apply penalty factor to software efficiency growth rate - leave for now\n",
    "\n",
    "automation_index=0\n",
    "\n",
    "### main loop\n",
    "if LOGGING:\n",
    "    run=wandb.init(project=\"FTM-implementation\")\n",
    "\n",
    "#the BL is a wonderful training environment\n",
    "\n",
    "for t in range (int(n_steps)):\n",
    "    year=2022+t\n",
    "\n",
    "    if t==0: #### initial\n",
    "\n",
    "        ###set initial state variables\n",
    "        GWP = GWP_0 \n",
    "        HS =  HS_0 \n",
    "        C_eff=C_eff_0 #initial stocks of effective compute\n",
    "        S=S_0\n",
    "        H=H_0\n",
    "\n",
    "        Cog_G=None\n",
    "        automation_index=None\n",
    "        C_T=f_C_T*C_eff\n",
    "\n",
    "        K = K_0 \n",
    "        L = L_0\n",
    "\n",
    "        RH_0=f_GWP_H*GWP_0\n",
    "        RH=RH_0\n",
    "        QH_0=(RH_0**lambda_H)/ratio_initial_cumulative_hardware_input ##FTM also multiplies by 1/lambda_H but idk why\n",
    "        QH=QH_0\n",
    "        g_QH=None \n",
    "\n",
    "        RS_0=f_GWP_S*GWP_0\n",
    "        RS=RS_0\n",
    "        QS_0=(RS**lambda_H)/ratio_initial_cumulative_software_input ##FTM also multiplies by 1/lambda_H but idk why\n",
    "        QS=QS_0\n",
    "        g_QS=None\n",
    "\n",
    "    else: #### update factors of production\n",
    "\n",
    "        #### non output variables\n",
    "        g_K=(s_K*GWP)/K\n",
    "        K=(1+g_K)*K #depreciation not implemented yet\n",
    "\n",
    "        #L \n",
    "        L = (1+g_L)*L\n",
    "    \n",
    "\n",
    "    if 1: #### ALLOCATIONS (static for now in this model)\n",
    "\n",
    "        #allocating compute\n",
    "        C_eff_GWP=f_C_GWP*C_eff #effective compute in GWP production\n",
    "\n",
    "        #allocating labour\n",
    "        L_GWP=f_L_GWP*L\n",
    "        L_H=f_L_H*L\n",
    "        L_HS=f_L_S*L\n",
    "\n",
    "        #allocating capital\n",
    "        K_GWP=f_K_GWP*K\n",
    "        K_H=f_K_H*K\n",
    "        K_S=f_K_S*K\n",
    "\n",
    "        #allocating compute \n",
    "        C_eff_GWP=f_C_GWP*C_eff\n",
    "        C_eff_H=f_C_H*C_eff\n",
    "        C_eff_S=f_C_S*C_eff\n",
    "        C_T= f_C_T*C_eff\n",
    "        \n",
    "    \n",
    "    if 1: #### set automation conditions (not differentiating between GWP and research for now)\n",
    "\n",
    "        C_T = f_C_T * C_eff #largest training run in this timestep (assuming training runs are instant)\n",
    "\n",
    "        ####automation (only done for G&S production)\n",
    "        automation_bools=automation_training_threshold<=C_T \n",
    "        automated_task_indices=np.arange(1,n_labour_tasks+1)[automation_bools]\n",
    "        if len(automated_task_indices)==0: automation_index=0\n",
    "        else:automation_index=automated_task_indices[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if GWP_ENDOGENEOUS: #production and GWP\n",
    "\n",
    "        if COGNITIVES_INPUT_ENDOGENOUS:\n",
    "            labour_per_task=L_GWP/n_labour_tasks #not allocating optimally yet\n",
    "\n",
    "            effective_compute_per_task = C_eff_GWP/(automation_index+1) #not allocating optimially, and not distinguishing between train and runtime effective compute\n",
    "\n",
    "            #labour and compute arrays\n",
    "            labour_array = np.concatenate(\\\n",
    "                (np.zeros(1),np.ones(n_labour_tasks) * labour_per_task),\\\n",
    "                axis=0\n",
    "                )\n",
    "            effective_compute_array = np.concatenate( \\\n",
    "                (np.ones(automation_index+1)*effective_compute_per_task,np.zeros(n_labour_tasks-automation_index)),\\\n",
    "                axis=0\n",
    "                )\n",
    "\n",
    "            if COMPUTE_RUNTIME_EFFICIENCIES:\n",
    "                eta_0 = 1/baseline_runtime_requirements\n",
    "                training_requirements_multiplier = (C_T/automation_training_threshold)**delta\n",
    "                eta = training_requirements_multiplier*eta_0\n",
    "\n",
    "                _eta_ = np.concatenate(\\\n",
    "                    (np.ones(1),eta),\n",
    "                    axis=0) #_eta_ adds the eta=1 for the compute only task\n",
    "\n",
    "\n",
    "            else:\n",
    "                    eta = np.ones(n_labour_tasks)*eta_0\n",
    "                    _eta_ = np.concatenate(\\\n",
    "                        (np.ones(1),eta),\n",
    "                        axis=0) #_eta_ adds the eta=1 for the compute only task\n",
    "\n",
    "\n",
    "\n",
    "            #inner weights\n",
    "            if COMPUTE_INNER_WEIGHTS:\n",
    "                if t==0:\n",
    "                    compute_to_labour_ratio=SC_0/SL_0\n",
    "                else:\n",
    "                    compute_to_labour_ratio = (beta_0/(n_labour_tasks*beta_i))*((C_eff_GWP*n_labour_tasks)/L_GWP)**(psi_G)\n",
    "                    omega_= compute_to_labour_ratio * ((L_GWP/(n_labour_tasks*C_eff_GWP))**psi_G)\n",
    "                    beta_0 = omega_/(1+omega_)\n",
    "                    beta_i = (1-beta_0)/n_labour_tasks\n",
    "\n",
    "                inner_weights = np.concatenate(\\\n",
    "                    (np.ones(1)*beta_0,np.ones(n_labour_tasks)*beta_i),\\\n",
    "                    axis=0\n",
    "                    )\n",
    "\n",
    "            else:\n",
    "                inner_weights = np.concatenate(\\\n",
    "                    (np.ones(1)*beta_0,np.ones(n_labour_tasks)*beta_i),\\\n",
    "                    axis=0\n",
    "                    )\n",
    "            \n",
    "            task_outputs = labour_array + (_eta_*effective_compute_array)\n",
    "            Cog_G = (np.sum(inner_weights*(task_outputs)**(psi_G)))**(1/psi_G) #compute->labour efficiencies NOT YET IMPLEMENTED\n",
    "        else:\n",
    "            Cog_G = 2.0e24\n",
    "\n",
    "        if COMPUTE_OUTER_WEIGHTS:\n",
    "            if t==0:\n",
    "                capital_to_cognitive_ratio=SK_0/SCog_0\n",
    "            else:\n",
    "                capital_to_cognitive_ratio = (alpha_G/(1-alpha_G))*((K_GWP/Cog_G)**rho_G)\n",
    "            omega=capital_to_cognitive_ratio*((Cog_G/K_GWP)**rho_G)\n",
    "            alpha_G=omega/(1+omega)\n",
    "        else:\n",
    "            alpha_G=alpha_G\n",
    "\n",
    "\n",
    "        production_gwp = TFP * (alpha_G*K_GWP**rho_G + (1-alpha_G)*Cog_G**rho_G)**(1/rho_G)\n",
    "\n",
    "        if t==0: #all we need is gwp_to_production ratio\n",
    "            gwp_to_production_ratio = GWP/production_gwp\n",
    "        else:\n",
    "            GWP=gwp_to_production_ratio * production_gwp\n",
    "\n",
    "    else:\n",
    "        if t==0: pass\n",
    "        else: GWP=(1+exg_g_GWP)*GWP #change GWP exogeneously\n",
    "\n",
    "\n",
    "    if H_ENDOGENEOUS:\n",
    "\n",
    "        \n",
    "                #hardware/software research production (only relevant if )\n",
    "        if RH_ENDOGENEOUS:\n",
    "            \n",
    "            if COGNITIVES_INPUT_ENDOGENOUS:\n",
    "\n",
    "                labour_per_task = L_H/n_labour_tasks #divide labour force for hardware research uniformly between tasks (not doing optimal allocation right now)\n",
    "                effective_compute_per_task = C_eff_H/n_labour_tasks\n",
    "                \n",
    "                #labour and compute arrays\n",
    "                labour_array = np.concatenate(\\\n",
    "                    (np.zeros(1),np.ones(n_labour_tasks) * labour_per_task),\\\n",
    "                    axis=0\n",
    "                    )\n",
    "                effective_compute_array = np.concatenate( \\\n",
    "                    (np.ones(automation_index+1)*effective_compute_per_task,np.zeros(n_labour_tasks-automation_index)),\\\n",
    "                    axis=0\n",
    "                    )\n",
    "\n",
    "            else:\n",
    "                Cog_H = 4.0e21 # but what does 'cognitive input' mean?\n",
    "\n",
    "            if COMPUTE_OUTER_WEIGHTS:\n",
    "                if t==0:\n",
    "                    pass\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                alpha_H=alpha_H\n",
    "\n",
    "            production_hardware = TFP * (alpha_H*K_H**rho_H + (1-alpha_H)*Cog_H**rho_H)**(1/rho_H)\n",
    "\n",
    "            if t==0:\n",
    "                RH_to_production_ratio  = RH/production_hardware\n",
    "            else:\n",
    "                RH = RH * production_hardware\n",
    "\n",
    "            if COMPUTE_OUTER_WEIGHTS: #Not implemented yet\n",
    "                pass\n",
    "            else:\n",
    "                alpha_H=alpha_H\n",
    "            \n",
    "            production_hardware = TFP * (alpha_H*K_H**rho_H + (1-alpha_H)*Cog_H**rho_H)**(1/rho_H)\n",
    "\n",
    "            if t==1:\n",
    "                hardware_to_production_ratio = RH_0/production_hardware\n",
    "\n",
    "            RH = hardware_to_production_ratio * production_hardware\n",
    "                \n",
    "        else: RH=(1+ex_g_RH)*RH\n",
    "\n",
    "        g_QH=(delta_T*(RH**lambda_H))/QH\n",
    "        QH=(1+g_QH)*QH\n",
    "\n",
    "        if HARDWARE_PENALTY_FACTOR:\n",
    "            pass\n",
    "        else:\n",
    "            g_H=rH*g_QH\n",
    "\n",
    "    else:\n",
    "\n",
    "        if t==0: pass\n",
    "        else:\n",
    "            g_QH=None #no cumulative hardware research required\n",
    "            H=(1+g_H)*H\n",
    "\n",
    "\n",
    "    if S_ENDOGENEOUS:\n",
    "\n",
    "        if RS_ENDOGENEOUS:\n",
    "\n",
    "            if COMPUTE_OUTER_WEIGHTS:\n",
    "                pass #not implemented\n",
    "            else:\n",
    "                alpha_S=alpha_S\n",
    "            \n",
    "            if COGNITIVES_INPUT_ENDOGENOUS: #not implemented\n",
    "                pass\n",
    "            else:\n",
    "                Cog_S = 4.0e20 #\n",
    "\n",
    "            production_software = TFP * (alpha_S*K_S**rho_S + (1-alpha_S)*Cog_S**rho_S)**(1/rho_S)\n",
    "\n",
    "            if t==1:\n",
    "                software_to_production_ratio = RS_0/production_software\n",
    "\n",
    "            RS = software_to_production_ratio * production_software\n",
    "\n",
    "        else: RS=(1+ex_g_RS)*RS\n",
    "\n",
    "        g_QS=(delta_T*(RS**lambda_H))/QS #stepping on toes parameter same for hardware and software research (man the abstractness of growth models is beautiful!)\n",
    "        QS=(1+g_QS)*QS\n",
    "\n",
    "        if SOFTWARE_PENALTY_FACTOR:\n",
    "            pass\n",
    "        else:\n",
    "            g_S=rS*g_QS\n",
    "\n",
    "    else:\n",
    "        if t==0: pass\n",
    "        else:\n",
    "            g_QS=None\n",
    "            S=(1+g_S)*S\n",
    "\n",
    "    #hardware stock and effective compute update \n",
    "    if t==0:\n",
    "        pass #do nothing on first pass\n",
    "    else:\n",
    "\n",
    "        g_HS = (f_GWP_H*GWP*H - HS_depreciation_rate*HS)/HS\n",
    "        HS = (1+g_HS)*HS; \n",
    "\n",
    "        C_eff = HS*S; \n",
    "\n",
    "    #logging\n",
    "    if LOGGING:\n",
    "        #we do this at the start to log initial values of variable\n",
    "        logging_dict['t']=t\n",
    "        logging_dict['year']=year\n",
    "\n",
    "        logging_dict['GWP (2022 $)']=GWP\n",
    "        logging_dict['HS (FLOP/year)']=HS\n",
    "        logging_dict['C_eff (2022 FLOP/year)']=C_eff\n",
    "        logging_dict['H (FLOP/$/year)']=H\n",
    "        logging_dict['S (2022 FLOP/FLOP/year)']=S\n",
    "\n",
    "        logging_dict['Cog_G (2022 $)']=Cog_G\n",
    "        logging_dict['Automation index']=automation_index\n",
    "        logging_dict['C_eff_T']=C_T\n",
    "\n",
    "        logging_dict['K (2022 $)']=K\n",
    "        logging_dict['L (HLY/year)']=L\n",
    "        logging_dict['Capital to cognitive share ratio']=capital_to_cognitive_ratio\n",
    "        logging_dict['alpha_G']=alpha_G\n",
    "        logging_dict['Compute to labour share ratio']=compute_to_labour_ratio\n",
    "        logging_dict['beta_0']=beta_0\n",
    "        logging_dict['beta_i']=beta_i\n",
    "\n",
    "        logging_dict['RH (2022 $)']=RH\n",
    "        logging_dict['QH (2022 USD)']=QH\n",
    "        logging_dict['g_H']=g_H\n",
    "        logging_dict['g_QH']=g_QH\n",
    "\n",
    "        logging_dict['RS (2022 $)']=RS\n",
    "        logging_dict['QS (2022 USD)']=QS\n",
    "        logging_dict['g_S']=g_S\n",
    "        logging_dict['g_QS']=g_QS\n",
    "\n",
    "\n",
    "        run.log(logging_dict)\n",
    "        \n",
    "if LOGGING:\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old stuff and experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hardware research production - NOT IN USE\n",
    "delta_t = 1\n",
    "r_H = 7.4286 #hardware efficiency returns to hardware R&D\n",
    "R_Hs = []\n",
    "\n",
    "\n",
    "#computing growth in cumulative research output\n",
    "K_H = f_K_H * K \n",
    "Cog_H = 4e21 #constant for now\n",
    "\n",
    "R_H = TFP * (alpha_H*K_H**rho_H + (1-alpha_H)*Cog_H**rho_H)**(1/rho_H)\n",
    "R_Hs = [R_H]*10 #for now, this is how we have list of annual hardware research\n",
    "\n",
    "\n",
    "Q_H_new = sum(R_Hs)\n",
    "Q_H_dot = (difference in Q_H)/delta_t\n",
    "\n",
    "g_QH = Q_H_dot/Q_H\n",
    "\n",
    "#computing penalty factor to efficiency growth rate\n",
    "'''\n",
    "intuition: Growth rate in technological (hardware or software)\n",
    "efficency should be modulated by a penalty factor. \n",
    "'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Software research production - NOT IN USE\n",
    "\n",
    "K_S = f_K_S * K \n",
    "Cog_S = f_Cog_S * Cog\n",
    "\n",
    "R_S = TFP * (alpha_S*K_S**rho_S + (1-alpha_S)*Cog_S**rho_S)**(1/rho_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Production function experiments\n",
    "\n",
    "TFP,alpha_G,K_GWP,Cog_GWP,rho_G = 1,0.0002,6.1e14,2.0e28,-0.4\n",
    "Y_1=alpha_G*K_GWP+(1-alpha_G)*Cog_GWP\n",
    "Y_2=alpha_G*K_GWP**rho_G+(1-alpha_G)*Cog_GWP**rho_G\n",
    "Y_3=(alpha_G*K_GWP**rho_G+(1-alpha_G)*Cog_GWP**rho_G)**(1/rho_G)\n",
    "Y_4=(K_GWP**rho_G + Cog_GWP**rho_G)**(1/rho_G)\n",
    "print(Y_1/1e13,Y_2,Y_3/1e13,Y_4/1e13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking factor shares\n",
    "KS,CogS = 0.5,0.5 #sum must equal to 1\n",
    "K_G,Cog_G,GWP,rho_G=6.1e14,2e24,8.5e13,-0.4\n",
    "omega_G=(KS/CogS) * ((Cog_G/K_G)**rho_G)\n",
    "alpha_G=omega_G/1+omega_G ###pretty much checks out\n",
    "print(alpha_G)\n",
    "\n",
    "\n",
    "## checking for capital share\n",
    "'''\n",
    "We know: KS = alpha * (K/Y)**rho_G\n",
    "'''\n",
    "alpha = KS*(GWP/K_G)**rho_G ##doesn't match alpha above\n",
    "print(alpha)\n",
    "\n",
    "Y_ = (alpha*(K_G**rho_G) + (1-alpha)*(Cog_G**rho_G))**(1/rho_G)\n",
    "\n",
    "## checking for cognitive share\n",
    "'''\n",
    "We know: CogS = (1-alpha)*(Cog_G/Y)**rho_G\n",
    "'''\n",
    "beta = CogS*((GWP/Cog_G)**rho_G)\n",
    "alpha=1-beta\n",
    "print(alpha)\n",
    "\n",
    "\n",
    "##working backward\n",
    "'''\n",
    "Plugging in values for GWP, K_G, Cog_G, rho_G, apparently alpha = 2.199892. \n",
    "Idk I'm really confused here.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cognitive output production - NOT IN USE\n",
    "\n",
    "n_labour_tasks=9\n",
    "automation_index = 5\n",
    "S=1\n",
    "HS=2e24\n",
    "C_eff=HS*S #effective compute (not factoring in a train-runtime traedeoff)\n",
    "L=4e9  #global workforce\n",
    "psi=-0.5 #substitution parameter amongst tasks for cognitive output production function\n",
    "eta_0 = 6e-23 #initial compute to labour efficiency\n",
    "\n",
    "#calculating task outputs - assuming uniform compute and labour allocation so far\n",
    "labour_allocation=[0]+list(np.repeat(L/n_labour_tasks,n_labour_tasks))\n",
    "task_automation_index = [1]+list(np.ones(automation_index,dtype=int)) + list(np.zeros(n_labour_tasks-automation_index,dtype=int))\n",
    "\n",
    "compute_allocation=list(np.repeat(C/(automation_index+1),automation_index+1)) + list(np.zeros(n_labour_tasks-automation_index))\n",
    "compute_to_labour_efficiencies=[1]+list(np.repeat(eta_0,n_labour_tasks)) #efficiences - constant for now\n",
    "zipped=list(zip(labour_allocation,compute_to_labour_efficiencies,compute_allocation))\n",
    "\n",
    "task_outputs=[tup[0]+tup[1]*tup[2] for tup in zipped]\n",
    "\n",
    "\n",
    "#computing cognitive outputs\n",
    "task_weights=list(np.repeat(1/(n_labour_tasks+1),n_labour_tasks+1)) #all tasks equally important for now\n",
    "weight_output_products=list((tup[0]*(tup[1]**psi) for tup in list(zip(task_weights,task_outputs))))\n",
    "Cog = sum(weight_output_products)**(1/psi)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m n_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mlen\u001b[39m(plot_dict))))\n\u001b[1;32m      2\u001b[0m fig,axs_matrix\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m),nrows\u001b[38;5;241m=\u001b[39mn_rows,ncols\u001b[38;5;241m=\u001b[39mn_rows)\n\u001b[1;32m      4\u001b[0m plot_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_dict' is not defined"
     ]
    }
   ],
   "source": [
    "n_rows=int(np.ceil(np.sqrt(len(plot_dict))))\n",
    "fig,axs_matrix=plt.subplots(figsize=(10,10),nrows=n_rows,ncols=n_rows)\n",
    "\n",
    "plot_num=0\n",
    "for ax_row in axs_matrix:\n",
    "    for ax in ax_row:\n",
    "        plot_key=list(plot_dict.keys())[plot_num]\n",
    "        ax.plot(plot_dict['t'],plot_dict[plot_key])\n",
    "        ax.set_ylabel(plot_key)\n",
    "\n",
    "        if plot_key=='t': ax.set_yscale('linear')\n",
    "        else: ax.set_yscale('log')\n",
    "        \n",
    "        plot_num+=1\n",
    "\n",
    "        if plot_num>=len(plot_dict):\n",
    "            break\n",
    "    if plot_num>=len(plot_dict):\n",
    "            break\n",
    "\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    if t==0: \n",
    "\n",
    "        ###allocations\n",
    "\n",
    "        #allocating compute\n",
    "        C_eff_GWP=f_C_GWP*C_eff #effective compute in GWP production\n",
    "\n",
    "        #allocating labour\n",
    "        L_GWP=f_L_GWP*L\n",
    "        L_H=f_L_H*L\n",
    "        L_HS=f_L_S*L\n",
    "\n",
    "        #allocating capital\n",
    "        K_GWP=f_K_GWP*K\n",
    "        K_H=f_K_H*K\n",
    "        K_S=f_K_S*K\n",
    "\n",
    "\n",
    "        ####set automation conditions\n",
    "        C_T = f_C_T * C_eff #largest training run in this timestep (assuming training runs are instant)\n",
    "\n",
    "        ####automation (only done for G&S production)\n",
    "        automation_bools=automation_training_threshold<=C_T \n",
    "        automated_task_indices=np.arange(1,n_labour_tasks+1)[automation_bools]\n",
    "        if len(automated_task_indices)==0: automation_index=0\n",
    "        else:automation_index=automated_task_indices[-1]\n",
    "\n",
    "        #done to compute gwp-to-production factor (need to do for all produced quantities)\n",
    "        if GWP_ENDOGENEOUS: #production and GWP\n",
    "\n",
    "            if COGNITIVES_INPUT_ENDOGENOUS:\n",
    "                labour_per_task=L_GWP/n_labour_tasks #not allocating optimally yet\n",
    "\n",
    "                effective_compute_per_task = C_eff_GWP/(automation_index+1) #not allocating optimially, and not distinguishing between train and runtime effective compute\n",
    "\n",
    "                #labour and compute arrays\n",
    "                labour_array = np.concatenate(\\\n",
    "                    (np.zeros(1),np.ones(n_labour_tasks) * labour_per_task),\\\n",
    "                    axis=0\n",
    "                    )\n",
    "                effective_compute_array = np.concatenate( \\\n",
    "                    (np.ones(automation_index+1)*effective_compute_per_task,np.zeros(n_labour_tasks-automation_index)),\\\n",
    "                    axis=0\n",
    "                    )\n",
    "\n",
    "                if COMPUTE_RUNTIME_EFFICIENCIES:\n",
    "                    eta_0 = 1/base_runtime_requirements\n",
    "                    training_requirements_multiplier = (C_T/automation_training_threshold)**delta\n",
    "                    eta = training_requirements_multiplier*eta_0\n",
    "\n",
    "                    _eta_ = np.concatenate(\\\n",
    "                        (np.ones(1),eta),\n",
    "                        axis=0) #_eta_ adds the eta=1 for the compute only task\n",
    "\n",
    "\n",
    "                else:\n",
    "                        eta = np.ones(n_labour_tasks)*eta_0\n",
    "                        _eta_ = np.concatenate(\\\n",
    "                            (np.ones(1),eta),\n",
    "                            axis=0) #_eta_ adds the eta=1 for the compute only task\n",
    "\n",
    "\n",
    "\n",
    "                #inner weights\n",
    "                if COMPUTE_INNER_WEIGHTS:\n",
    "                    compute_to_labour_ratio=SC_0/SL_0\n",
    "                    omega_= compute_to_labour_ratio * ((L_GWP/(n_labour_tasks*C_eff_GWP))**psi_G)\n",
    "                    beta_0 = omega_/(1+omega_)\n",
    "                    beta_i = (1-beta_0)/n_labour_tasks\n",
    "\n",
    "                    inner_weights = np.concatenate(\\\n",
    "                        (np.ones(1)*beta_0,np.ones(n_labour_tasks)*beta_i),\\\n",
    "                        axis=0\n",
    "                        )\n",
    "\n",
    "                else:\n",
    "                    inner_weights = np.concatenate(\\\n",
    "                        (np.ones(1)*beta_0,np.ones(n_labour_tasks)*beta_i),\\\n",
    "                        axis=0\n",
    "                        )\n",
    "                \n",
    "                task_outputs = labour_array + (_eta_*effective_compute_array)\n",
    "                Cog_G = (np.sum(inner_weights*(task_outputs)**(psi_G)))**(1/psi_G) #compute->labour efficiencies NOT YET IMPLEMENTED\n",
    "            else:\n",
    "                Cog_G = 2.0e24\n",
    "\n",
    "            if COMPUTE_OUTER_WEIGHTS:\n",
    "                capital_to_cognitive_ratio=SK_0/SCog_0\n",
    "                omega=capital_to_cognitive_ratio*((Cog_G/K_GWP)**rho_G)\n",
    "                alpha_G=omega/(1+omega)\n",
    "            else:\n",
    "                alpha_G=alpha_G\n",
    "\n",
    "\n",
    "            production_gwp = TFP * (alpha_G*K_GWP**rho_G + (1-alpha_G)*Cog_G**rho_G)**(1/rho_G)\n",
    "\n",
    "            if t==0:\n",
    "                gwp_to_production_ratio = GWP/production_gwp\n",
    "            else:\n",
    "                GWP=gwp_to_production_ratio * production_gwp\n",
    "\n",
    "            GWP=GWP\n",
    "\n",
    "        else: GWP=GWP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ####### IF T NOT EQUAL 0\n",
    "    else: \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        #allocating compute\n",
    "        C_eff_GWP=f_C_GWP*C_eff #effective compute in GWP production\n",
    "\n",
    "        #allocating labour\n",
    "        L_GWP=f_L_GWP*L\n",
    "        L_H=f_L_H*L\n",
    "        L_HS=f_L_S*L\n",
    "\n",
    "        #allocating capital\n",
    "        K_GWP=f_K_GWP*K\n",
    "        K_H=f_K_H*K\n",
    "        K_S=f_K_S*K\n",
    "\n",
    "        ####set automation conditions\n",
    "        C_T = f_C_T * C_eff #largest training run in this timestep (assuming training runs are instant)\n",
    "\n",
    "\n",
    "\n",
    "        ####automation (only done for G&S production)\n",
    "        automation_bools=automation_training_threshold<=C_T \n",
    "        automated_task_indices=np.arange(1,n_labour_tasks+1)[automation_bools]\n",
    "        if len(automated_task_indices)==0: automation_index=0\n",
    "        else:automation_index=automated_task_indices[-1]\n",
    "\n",
    "        #### production\n",
    "        if GWP_ENDOGENEOUS: #production and GW\n",
    "\n",
    "            if COGNITIVES_INPUT_ENDOGENOUS:\n",
    "                labour_per_task=L_GWP/n_labour_tasks #not allocating optimally yet\n",
    "\n",
    "                ###compute HLH-to-compute effiencies\n",
    "                effective_compute_per_task = C_eff_GWP/(automation_index+1) #not allocating optimially, and not distinguishing between train and runtime effective compute\n",
    "\n",
    "                #labour and compute arrays\n",
    "                labour_array = np.concatenate(\\\n",
    "                    (np.zeros(1),np.ones(n_labour_tasks) * labour_per_task),\\\n",
    "                    axis=0\n",
    "                    )\n",
    "                effective_compute_array = np.concatenate( \\\n",
    "                    (np.ones(automation_index+1)*effective_compute_per_task,np.zeros(n_labour_tasks-automation_index)),\\\n",
    "                    axis=0,\n",
    "                    )\n",
    "\n",
    "                if COMPUTE_RUNTIME_EFFICIENCIES:\n",
    "                    eta_0 = 1/base_runtime_requirements\n",
    "                    training_requirements_multiplier = (C_T/automation_training_threshold)**delta\n",
    "                    eta = training_requirements_multiplier*eta_0\n",
    "\n",
    "                    _eta_ = np.concatenate(\\\n",
    "                        (np.ones(1),eta),\n",
    "                        axis=0) #_eta_ adds the eta=1 for the compute only task\n",
    "\n",
    "                else:\n",
    "                        eta = np.ones(n_labour_tasks)*eta_0\n",
    "                        _eta_ = np.concatenate(\\\n",
    "                            (np.ones(1),eta),\n",
    "                            axis=0)\n",
    "\n",
    "\n",
    "\n",
    "                #inner weights\n",
    "                if COMPUTE_INNER_WEIGHTS:\n",
    "                    compute_to_labour_ratio = (beta_0/n_labour_tasks*beta_i)*(C_eff_GWP*n_labour_tasks/L_GWP)**(psi_G)\n",
    "                    omega = compute_to_labour_ratio * ((L_GWP/n_labour_tasks*C_eff_GWP)**psi_G)\n",
    "                    beta_0 = omega_/(1+omega_)\n",
    "                    beta_i = (1-beta_0)/n_labour_tasks\n",
    "\n",
    "                    inner_weights = np.concatenate(\\\n",
    "                        (np.ones(1)*beta_0,np.ones(n_labour_tasks)*beta_i),\\\n",
    "                        axis=0\n",
    "                        )\n",
    "\n",
    "                else:\n",
    "                    inner_weights = np.concatenate(\\\n",
    "                        (np.ones(1)*beta_0,np.ones(n_labour_tasks)*beta_i),\\\n",
    "                        axis=0\n",
    "                        )\n",
    "\n",
    "                task_outputs = labour_array + (_eta_*effective_compute_array)\n",
    "                Cog_G = (np.sum(inner_weights*(task_outputs)**(psi_G)))**(1/psi_G)\n",
    "\n",
    "            else:\n",
    "                Cog_G = (1+g_Cog)*Cog_G\n",
    "\n",
    "            if COMPUTE_OUTER_WEIGHTS:\n",
    "\n",
    "                ##compute new task share ratio\n",
    "                capital_to_cognitive_ratio = (alpha_G/(1-alpha_G))*((K_GWP/Cog_G)**rho_G)\n",
    "                omega=capital_to_cognitive_ratio*((Cog_G/K_GWP)**rho_G)\n",
    "                alpha_G=omega/(1+omega)\n",
    "\n",
    "            else:\n",
    "                alpha_G=alpha_G\n",
    "\n",
    "            production_gwp = TFP * (alpha_G*K_GWP**rho_G + (1-alpha_G)*Cog_G**rho_G)**(1/rho_G)\n",
    "\n",
    "            GWP=gwp_to_production_ratio * production_gwp #normalise production\n",
    "            \n",
    "        else: GWP=(1+exg_g_GWP)*GWP\n",
    "\n",
    "\n",
    "        if H_ENDOGENEOUS:\n",
    "\n",
    "                    #hardware/software research production (only relevant if )\n",
    "            if RH_ENDOGENEOUS:\n",
    "\n",
    "                if COMPUTE_OUTER_WEIGHTS: #Not implemented yet\n",
    "                    pass\n",
    "                else:\n",
    "                    alpha_H=alpha_H\n",
    "                \n",
    "                if COGNITIVES_INPUT_ENDOGENOUS: #not implemented\n",
    "                    Cog_H=None \n",
    "                else:\n",
    "                    Cog_H = 4.0e21 # but what does 'cognitive input' mean?\n",
    "\n",
    "                production_hardware = TFP * (alpha_H*K_H**rho_H + (1-alpha_H)*Cog_H**rho_H)**(1/rho_H)\n",
    "\n",
    "                if t==1:\n",
    "                    hardware_to_production_ratio = RH_0/production_hardware\n",
    "\n",
    "                RH = hardware_to_production_ratio * production_hardware\n",
    "                    \n",
    "            else: RH=(1+ex_g_RH)*RH\n",
    "\n",
    "            g_QH=(delta_T*(RH**lambda_H))/QH\n",
    "            QH=(1+g_QH)*QH\n",
    "\n",
    "            if HARDWARE_PENALTY_FACTOR:\n",
    "                pass\n",
    "            else:\n",
    "                g_H=rH*g_QH\n",
    "\n",
    "        else:\n",
    "            g_QH=None #no cumulative hardware research required\n",
    "            H=(1+g_H)*H\n",
    "\n",
    "        if S_ENDOGENEOUS:\n",
    "\n",
    "            if RS_ENDOGENEOUS:\n",
    "\n",
    "                if COMPUTE_OUTER_WEIGHTS:\n",
    "                    pass #not implemented\n",
    "                else:\n",
    "                    alpha_S=alpha_S\n",
    "                \n",
    "                if COGNITIVES_INPUT_ENDOGENOUS: #not implemented\n",
    "                    pass\n",
    "                else:\n",
    "                    Cog_S = 4.0e20 #\n",
    "\n",
    "                production_software = TFP * (alpha_S*K_S**rho_S + (1-alpha_S)*Cog_S**rho_S)**(1/rho_S)\n",
    "\n",
    "                if t==1:\n",
    "                    software_to_production_ratio = RS_0/production_software\n",
    "\n",
    "                RS = software_to_production_ratio * production_software\n",
    "\n",
    "            else: RS=(1+ex_g_RS)*RS\n",
    "\n",
    "            g_QS=(delta_T*(RS**lambda_H))/QS #stepping on toes parameter same for hardware and software research (man the abstractness of growth models is beautiful!)\n",
    "            QS=(1+g_QS)*QS\n",
    "\n",
    "            if SOFTWARE_PENALTY_FACTOR:\n",
    "                pass\n",
    "            else:\n",
    "                g_S=rS*g_QS\n",
    "\n",
    "        else:\n",
    "            g_QS=None\n",
    "            S=(1+g_S)*S\n",
    "\n",
    "        #hardware stock and effective compute update \n",
    "        \n",
    "        g_HS = (f_GWP_compute*GWP*H - HS_depreciation_rate*HS)/HS\n",
    "        HS = (1+g_HS)*HS; \n",
    "\n",
    "        C_eff = HS*S; "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('FTM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f33f59546c507a35a4881afce9503208f6c8f0e8d914c07bf4768a8e3992010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
